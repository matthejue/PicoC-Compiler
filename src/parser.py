from errors import MismatchedTokenError
from ast_builder import ASTBuilder
from abstract_syntax_tree import TokenNode


class BacktrackingParser():

    """Analyzes the syntactic structure of a token sequence generated by the
    Lexer using theoretically infinitely many lookahead tokens and is
    furthermore able to backtrack and thus able to also distinguish rules which
    have the same identical syntactical structure for their first finitely many
    tokens"""

    def __init__(self, lexer):
        """
        :lts: lookahead tokens
        :num_lts: number of lookahead tokens
        :lt_idx: lookahead token index

        """
        self.lexer = lexer
        self.markers = []
        self.lts = []
        self.lt_idx = 0
        self.ast_builder = ASTBuilder()

    def LT(self, i):
        """Lookahead Token

        :returns: find out token looking ahead i tokens
        """
        self._sync(i)
        return self.lts[self.p + i - 1]

    def LTT(self, i):
        """Lookahead tokentype

        :returns: find out type locking ahead i tokens
        """
        return self.LT(i).type

    def match(self, tts):
        """Check if one of the tts are the next token in the lexer to match. In
        general checks if non-terminal symbols are at the right syntactial
        sition

        :tts: possibly matching tokentypes (because of symbols like e.g. '-')
        :returns: None, possibly an exception
        """
        if (self.LTT(1) in tts):
            self._consume_next_token()
        else:
            raise MismatchedTokenError("'" + tts.value + "'", self.LT(1))

    def match_and_add(self, tts):
        """Add the current token to the ast and check for match

        :tts: possibly matching tokentypes (because of symbols like e.g. '-')
        :returns: None, possibly an exception
        """
        # if (self.ast_builder.current_node.token not in tts):
        self.ast_builder.addChild(TokenNode(self.LT(1)))
        self.match(tts)

    def _sync(self, i):
        """ensures that there're going to be i tokens from current position
        lt_idx

        :returns: None

        """
        if self.lt_idx + i - 1 > len(self.lts)-1:
            not_filled_up = (self.lt_idx + i - 1) - (len(self.lts) - 1)
            self._fill(not_filled_up)

    def _fill(self, not_filled_up):
        """add not_filled_up many tokens

        :grammar: grammar specification
        :returns: None

        """
        for i in range(0, not_filled_up):
            self.lt += [self.lexer.next_token()]

    def _consume_next_token(self):
        """fills next position in the lookahead tokenlist with token

        :returns: None

        """
        self.lt_idx += 1
        if self.lt_idx == len(self.lts) and not self._is_tasting():
            self.lt_idx == 0
            self.lts = []
        self._sync(1)

    def _mark(self):
        """rememeber with a marker index where the last taste method call occured

        :returns: None

        """
        self.markers += [self.lt_idx]
        return self.lt_idx

    def _release(self):
        """go the the last remembered marker and forget about it

        :returns: None

        """
        marker = self.markers.pop()
        # self.seek(marker)
        # seek:
        self.lt_idx = marker

    def _is_tasting(self):
        """if in the taste method every mark() found his corresponding
        release()

        :returns: boolean

        """
        return len(self.markers) > 0

    def taste(self, rule):
        """Tries ("tastes") out alternative and says whether it will raise a
        exception so one can go on and try out the next alternative. Is used in
        case of syntactically undistinguishable grammar rules.

        :returns: boolean

        """
        tastes_good = True
        self._mark()
        try:
            rule()
        except Exception:
            tastes_good = False
        self._release()
        return tastes_good


# class LL_Recursive_Decent_Parser:

    # """Analyzes the syntactic structure of a token sequence generated by the
    # Lexer using  k>1 lookahead tokens
    # """

    # def __init__(self, lexer, num_lts):
        # """
        # :lts: lookahead tokens
        # :num_lts: number of lookahead tokens
        # :lt_idx: lookahead token index

        # """
        # self.lexer = lexer
        # self.num_lts = num_lts
        # self.lts = [0] * self.num_lts
        # self.lt_idx = 0
        # for _ in range(self.num_lts):
        # self.next_token()
        # self.ast_builder = ASTBuilder()

    # def next_token(self):
        # """fills next position in the lookahead tokenlist with token

        # :returns: None
        # """
        # self.lts[self.lt_idx] = self.lexer.next_token()
        # self.lt_idx = (self.lt_idx + 1) % self.num_lts

    # def LT(self, i):
        # """Lookahead Token

        # :returns: find out token looking ahead i tokens
        # """
        # return self.lts[(self.lt_idx + i - 1) % self.num_lts]

    # def LTT(self, i):
        # """Lookahead tokentype

        # :returns: find out type locking ahead i tokens
        # """
        # return self.LT(i).type

    # def match(self, tts):
        # """Check if one of the tts are the next token in the lexer to match. In
        # general checks if non-terminal symbols are at the right syntactial
        # position

        # :tts: possibly matching tokentypes (because of symbols like e.g. '-')
        # :returns: None, possibly an exception
        # """
        # if (self.LTT(1) in tts):
        # self.next_token()
        # else:
        # raise SyntaxError("'" + tts.value + "'", self.LT(1))

    # def match_and_add(self, tts):
        # """Add the current token to the ast and check for match

        # :tts: possibly matching tokentypes (because of symbols like e.g. '-')
        # :returns: None, possibly an exception
        # """
        # # if (self.ast_builder.current_node.token not in tts):
        # self.ast_builder.addChild(TokenNode(self.LT(1)))
        # self.match(tts)
